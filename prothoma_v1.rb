require 'nokogiri'
require 'httparty'
require 'byebug'
require 'csv'
#require 'pry'
require 'selenium-webdriver'
#require 'language_converter'
def scraper

#puts "Give the URL"
#url = gets.chomp
url ="https://www.prothoma.com/publisher"
url= url+"?page=1"
unparsed_page = HTTParty.get(url)
parsed_page = Nokogiri::HTML(unparsed_page.body)
pub_list = parsed_page.css('div.category_list_single_block')

publisher_array = Array.new

pub_first_page =20
pub_last_page =22
a =url
while pub_first_page <= pub_last_page

  x= a.delete_suffix(a[-1]) + "#{pub_first_page}"

  pagination_url = x

  unparsed_page = HTTParty.get(pagination_url)
  parsed_page = Nokogiri::HTML(unparsed_page.body)

  pagination_pub_list = parsed_page.css('div.category_list_single_block')
#byebug
  pagination_pub_list.each do |publisher|
    publisher = {
    #name: publisher.css('div.category_info_ct_block').text,
    url: publisher.css('a')[0].attributes["href"].value

  }
  publisher_array << publisher

end
pub_first_page += 1

end
      # CSV.open("csv/publisher.csv",'w') do |csv|
      #   csv << ['Title','URL']
      #   publisher_array.each do |product|
      #     #product = temp.merge(product)
      #     csv << CSV::Row.new(product.keys,product.values)
      #   end
      # end



  publisher_array.each do |pub_url|
    # puts "Give the URL"
    # url = gets.chomp

    url= pub_url.values[0] +"?page=1"
    #byebug
    driver = Selenium::WebDriver.for :chrome
    driver.navigate.to "#{url}"
    wait = Selenium::WebDriver::Wait.new(:timeout => 10)
    wait.until {  driver.find_elements(:class, "product-amount")[0].text.split(" ")[0] !=nil }
    a = driver.find_elements(:class, "product-amount")[0].text.split(" ")[0]

    #a ='৪৭০১৫৬২০১৩৮৯'

    def converter(a)
      a.slice!(" টাকা")
      #byebug
      z = a.split("")

      b1= { "১"=> "1" ,"২"=> "2"  ,"৩"=> "3" ,"৪"=> "4" ,"৫"=> "5" ,
            "৬"=> "6" ,"৭"=> "7" ,"৮"=> "8" ,"৯"=> "9" ,"০"=> "0",
            "."=> ".",","=> ","  }
      c=[]
      z.each do |x|
         y = x.to_s
         c << b1[y]
      end
      st =""
      c.map do |x|
        st = st+x
      end
      st
    end
    a= converter(a)
    total_products = a.to_i
    # puts total_products
    # byebug

    unparsed_page = HTTParty.get(url)
    parsed_page = Nokogiri::HTML(unparsed_page.body)
    product_array = Array.new
    products = parsed_page.css('div.product_single')
    per_page = products.count
    page = 1
    if total_products > 0
      last_page = (total_products.to_f / per_page.to_f).ceil
    else
      last_page= page
    end
    #last_page = (total_products.to_f / per_page.to_f).ceil

    n=0
    publisher =parsed_page.css('div.media-body').text.gsub(/\n/," ").strip
    a = url
    while page <= last_page

      x= a.delete_suffix(a[-1]) + "#{page}"

      pagination_url = x

      pagination_unparsed_page = HTTParty.get(pagination_url)
      pagination_parsed_page = Nokogiri::HTML(pagination_unparsed_page.body)
      pagination_products = pagination_parsed_page.css('div.product_single')

      pagination_products.each  do|product|
        product ={
          title: product.css('h2').text,
          author: product.css('h3').text,
          original_price: product.css('span.price_2').text,
          discounted_price: product.css('span.price_1').text,
          url: product.css('a')[0].attributes["href"].text,
          image: product.css('img')[0].attributes["src"].text
        }
        #convertion of bangla to english
        product[:original_price] = converter(product[:original_price])
        product[:discounted_price] = converter( product[:discounted_price])
        #if original is not available
        if product[:original_price] == ""
          product[:original_price] = product[:discounted_price]
          product[:discounted_price]= ""
        end
        # byebug

        product_array << product
      end
      page += 1
    end

    temp = {
          title: " ",
          author: "",
          original_price: " ",
          discounted_price: " ",
          url: " ",
          image: " ",
          summary: " ",
          "Title" => " ",
          "Author"=>" ",
          "Translator"=>" ",
          "Editor" => " ",
          "Publisher"=>" ",
          "ISBN"=>" ",
          "Edition"=>" ",
          "Number of Pages"=>" ",
          "Country"=>" ",
          "Language"=>" "


        }
     #byebug
      CSV.open("prothoma_v1/#{publisher}.csv",'w') do |csv|
        csv << ['Title','Author','Original Price','Discounted Price','URL','Image','Summary','Book_Title','Book_Author','Translator','Editor','Publisher','ISBN','Edition','Number Of Pages','Country','Language']
        product_array.each do |product|
          product = temp.merge(product)
          #byebug
          csv << CSV::Row.new(product.keys,product.values)
        end
      end
      # byebug
      driver.quit
      puts "#{publisher}.csv is created"

  end
end
scraper
